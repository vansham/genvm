# yaml-language-server: $schema=../../../doc/schemas/default-config.json#llm
# yaml-language-server: $schema=https://raw.githubusercontent.com/yeagerai/genvm/refs/heads/main/doc/schemas/default-config.json#llm

bind_address: 127.0.0.1:3031

lua_script_path: ${exeDir}/../config/genvm-llm-default.lua
vm_count: 6
lua_path: ${exeDir}/../lib/genvm-lua/?.lua
signer_url: "http://localhost:9155/genvm/sign"
signer_headers: {}

threads: 4
blocking_threads: 16
log_disable: tracing*,polling*,tungstenite*,tokio_tungstenite*
#log_level: info

backends:
  openai:
    host: https://api.openai.com
    provider: openai-compatible
    key: ${ENV[OPENAIKEY]}
    models:
      gpt-4o:
        supports_json: true
        supports_image: true # works
        meta: {} # <- you can put anything here to read it from lua

  heurist:
    host: https://llm-gateway.heurist.xyz
    provider: openai-compatible
    key: ${ENV[HEURISTKEY]}
    models:
      meta-llama/llama-3.3-70b-instruct:
        supports_json: true
        supports_image: false # this model does not support images

  anthropic:
    enabled: true
    host: https://api.anthropic.com
    provider: anthropic
    key: ${ENV[ANTHROPICKEY]}
    models:
      claude-3-7-sonnet-20250219:
        supports_json: false # it is quite bad because it wraps result into random "result/value/object/..."
        supports_image: true # works

  xai:
    host: https://api.x.ai
    provider: openai-compatible
    key: ${ENV[XAIKEY]}
    models:
      grok-2-1212:
        supports_json: true
        supports_image: false # hallucinates

  google:
    host: https://generativelanguage.googleapis.com
    provider: google
    key: ${ENV[GEMINIKEY]}
    models:
      gemini-2.5-flash:
        supports_json: true
        supports_image: true # works

  atoma:
    enabled: false
    host: https://api.atoma.network
    provider: openai-compatible
    key: ${ENV[ATOMAKEY]}
    models:
      meta-llama/Llama-3.3-70B-Instruct:
        supports_json: true

prompt_templates:
  eq_comparative:
    system: |
        You are an a judge tasked with making a binary determination about whether two outputs satisfy the given comparison criteria.
        You are given two potential outputs to compare: the primary output and the comparison output.
        You must evaluate strictly based on the provided comparison criteria without introducing external criteria or assumptions.
        Your evaluation must be rigorous and thorough, as the stakes are high.

    user: |
        Input sections:
        <primary_output>
        #{leader_answer}
        </primary_output>

        <comparison_output>
        #{validator_answer}
        </comparison_output>

        <comparison_criteria>
        #{principle}
        </comparison_criteria>

        Evaluation rules:

        1. If any section is missing or empty, return false
        2. Both outputs must satisfy ALL comparison criteria completely - partial satisfaction is insufficient
        3. If there is ANY ambiguity about whether a criterion is met, return false
        4. Evaluate using ONLY the explicitly stated comparison criteria
        5. Formatting differences alone do not affect equivalence unless specified in the criteria
        6. Do not make assumptions about unstated criteria or requirements

        Output format:
        Respond with json object containing key "result" and associated boolean value,
        representing the result of evaluating above criteria. And string field "reason",
        which contains extremely concise reason for decision. Reason should precede result.

        Examples:
        {"reason": "all rules satisfied", "result": true}
        {"reason": "rule 2 violated: ...", "result": false}

        Output must have only these two fields and not be wrapped in other objects.
  eq_non_comparative_leader:
    system: |
      You must perform given task for the input. Result must satisfy all of the criteria listed below
      You are tasked with performing a "task" for the given "input", your evaluation result (output) must be and satisfy all given criteria.
      You must evaluate strictly based on the provided comparison criteria and task without introducing external criteria or assumptions.
      Your result must be rigorous and thorough, as it's conformity will be evaluated in future.
    user: |
      Input sections:
      <task>
      #{task}
      </task>

      <criteria>
      #{criteria}
      </criteria>

      <input>
      #{input}
      </input>

      Evaluation rules:

      1. Output must satisfy ALL comparison criteria completely - partial satisfaction is insufficient
      2. There must be NO ambiguity about whether a criterion is met
      3. Evaluate using ONLY the explicitly stated criteria and a task
      4. Do not make assumptions about unstated criteria or requirements

      Output format:
      Respond only with: the result of performing the task, do not include reasoning or evaluation rules satisfaction.
      If task requires outputting json, output valid parsable json without extra symbols.
  eq_non_comparative_validator:
    system: |
      You are an a judge tasked with making a binary determination about whether task evaluation result (output) is valid for the given input and satisfies given criteria.
      You must evaluate strictly based on the provided comparison criteria and task without introducing external criteria or assumptions.
      Your evaluation must be rigorous and thorough, as the stakes are high.

    user: |
      Input sections:
      <task>
      #{task}
      </task>

      <input>
      #{input}
      </input>

      <criteria>
      #{criteria}
      </criteria>

      <output>
      #{output}
      </output>

      Evaluation rules:

      1. If any section is missing or empty, return false
      2. Output must satisfy ALL comparison criteria completely - partial satisfaction is insufficient
      3. If there is ANY ambiguity about whether a criterion is met, return false
      4. Evaluate using ONLY the explicitly stated criteria and a task
      5. Formatting differences alone do not affect the result unless specified in the criteria
      6. Do not make assumptions about unstated criteria or requirements

      Output format:
      Respond with json object containing key "result" and associated boolean value,
      representing the result of evaluating above criteria. And string field "reason",
      which contains extremely concise reason for decision. Reason should precede result.

      Examples:
      {"reason": "all rules satisfied", "result": true}
      {"reason": "rule 1 violated: section input is empty", "result": false}
      {"reason": "criteria not met: <explanation>", "result": false}

      Output must have only these two fields and not be wrapped in other objects.
